{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, '')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from timeit import default_timer as timer\n",
    "import datetime\n",
    "import math\n",
    "import os\n",
    "\n",
    "# Settings\n",
    "video_addr='/home/unumkam/Desktop/repos/data/2020-12-29 12-22-31.181.wmv'\n",
    "turn_on_delay = 5\n",
    "x,y = 200,190\n",
    "w,h = 1070,150\n",
    "frames_limit = 10\n",
    "detection_zones = 6\n",
    "bound_velocity = 0.006 #8\n",
    "\n",
    "# Common memory\n",
    "measures = [ [ 0 for i in range(detection_zones) ] for j in range(frames_limit) ]\n",
    "errorDelayCounters = [0]*detection_zones\n",
    "\n",
    "\n",
    "def printLabel( image, label ):\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX \n",
    "    # org \n",
    "    org = (50, 50) \n",
    "    # fontScale \n",
    "    fontScale = 1\n",
    "    # Blue color in BGR \n",
    "    color = (255, 0, 0) \n",
    "  \n",
    "    # Line thickness of 2 px \n",
    "    thickness = 2\n",
    "    return cv2.putText(image, label, org, font,  \n",
    "                   fontScale, color, thickness, cv2.LINE_AA)\n",
    "\n",
    "def process_zone( zone_index, image):\n",
    "    array=measures[zone_index]\n",
    "    wasFound = False\n",
    "    speedFactor = 0.0\n",
    "    widthFactor = 0.0\n",
    "    fullArea = image.shape[0]*image.shape[1]\n",
    "    area = cv2.countNonZero(image)\n",
    "    ratio = area/fullArea\n",
    "    if( len(array) > frames_limit):\n",
    "        measures[zone_index].pop(0)\n",
    "    measures[zone_index].append(ratio)\n",
    "    array=measures[zone_index]\n",
    "    f_min = min(array)\n",
    "    f_max = max(array)\n",
    "    diffs = []\n",
    "    if( len(array) == 1):\n",
    "        return False,0,0\n",
    "    for index in range(0,len(array)-1):\n",
    "        diffs.append(math.fabs(array[index]-array[index+1]))\n",
    "    if( max(diffs) > bound_velocity ):\n",
    "        wasFound = True\n",
    "    return wasFound,  max(diffs), f_max-f_min\n",
    "            \n",
    "        \n",
    "def detect_artifacts(binarized_image,zones_count,x,y,w,h):\n",
    "    answer = []\n",
    "    for zone_index in range(0,zones_count):\n",
    "        zone_width = int(w/zones_count)\n",
    "        rect_x = x + zone_index*zone_width\n",
    "        cropped_zone = binarized_image[y+1:y+h-2,rect_x:rect_x+zone_width-2]\n",
    "        wasFound,diff_rate,amp_rate=process_zone(zone_index, cropped_zone)\n",
    "        answer.append((wasFound,diff_rate))\n",
    "    return answer\n",
    "\n",
    "def addZoneRect(color_image, zone_index, zones_count, green_or_red, x,y,w,h ):\n",
    "    zone_width = int(w/zones_count)\n",
    "    rect_x = x + zone_index*zone_width\n",
    "    color = ((1,255,1),(1,1,255))[green_or_red]\n",
    "    dept=(4,1)[green_or_red]\n",
    "    return cv2.rectangle(color_image,(rect_x,y),(rect_x+zone_width,y+h),color,dept)\n",
    "    \n",
    "    \n",
    "def process_video_file():\n",
    "    # Focusing delay\n",
    "    start = timer()\n",
    "    error = False\n",
    "    errorText = \"\"\n",
    "        \n",
    "    cap = cv2.VideoCapture(video_addr)\n",
    "    if not cap.isOpened():\n",
    "        return True, \"Error opening video stream or file\"\n",
    "    \n",
    "    images = []\n",
    "    \n",
    "    while(cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        if ret == False:\n",
    "            break\n",
    "        gr_img = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        ret,binarizedImage = cv2.threshold(gr_img,215,255,cv2.THRESH_TOZERO)\n",
    "        color_img = cv2.cvtColor(binarizedImage, cv2.COLOR_GRAY2RGB)\n",
    "        \n",
    "        images.append(gr_img)\n",
    "        if( len(images)>3 ):\n",
    "            images.pop(0)\n",
    "            \n",
    "        if( len(images)==3):      \n",
    "            # im_t is the frame of interest; im_tp1 and im_tm1 are, respectively\n",
    "            # the successive and previous frames.\n",
    "            dbp = cv2.absdiff(images[1], images[0])\n",
    "            db0 = cv2.absdiff(images[2], images[0])\n",
    "            dbm = cv2.absdiff(images[1],images[2])\n",
    "            detect = cv2.bitwise_not( cv2.bitwise_and(cv2.bitwise_and(dbp, dbm),cv2.bitwise_not(db0)))\n",
    "            r,bb = cv2.threshold(detect,215,255,cv2.THRESH_TOZERO_INV)\n",
    "            thresh_frame = cv2.dilate(bb, None, iterations = 2) \n",
    "            cv2.imshow('Original44',bb)\n",
    "            cv2.imshow('Original46',thresh_frame)\n",
    "            binarizedImage = thresh_frame\n",
    "        \n",
    "        is_ready =  timer() - start > turn_on_delay\n",
    "        \n",
    "        label = \"\"\n",
    "        if is_ready:\n",
    "            answer_metrics_pairs = detect_artifacts( binarizedImage, detection_zones,x,y,w,h)\n",
    "            for zone_index in range(detection_zones):\n",
    "                (answer,metrics)=answer_metrics_pairs[zone_index]\n",
    "                label = label +(\"Y\",\"N\")[answer]+\" \"+\"{:.5f}\".format(metrics)+\" \"\n",
    "                longError =  errorDelayCounters[zone_index] > 0\n",
    "                if longError:\n",
    "                    answer = True\n",
    "                    errorDelayCounters[zone_index] =  errorDelayCounters[zone_index] - 1\n",
    "                elif answer:\n",
    "                    errorDelayCounters[zone_index] = 4\n",
    "                color_img = addZoneRect( color_img, zone_index, detection_zones, answer, x,y,w,h)\n",
    "        else:\n",
    "            label = \"focusing delay\"\n",
    "        \n",
    "        finalImage = printLabel(color_img, label)\n",
    "        cv2.imshow('Original',frame)\n",
    "        cv2.imshow('Frame',finalImage)\n",
    "                \n",
    "        # Press Q on keyboard to  exit\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # When everything done, release the video capture object\n",
    "    cap.release()\n",
    "\n",
    "    # Closes all the frames\n",
    "    cv2.destroyAllWindows()\n",
    "    return False,\"\"\n",
    "\n",
    "process_video_file()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-e0c14f8febe8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Capture frame-by-frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Our operations on the frame come here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Open camera\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "while(True):\n",
    "    cap.set(7, 0)\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Our operations on the frame come here\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame',gray)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
