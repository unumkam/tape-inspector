{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from timeit import default_timer as timer\n",
    "import datetime\n",
    "import math\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# data\n",
    "cwd = os.getcwd()\n",
    "examples_dir = cwd + \"\\\\video\\\\\"\n",
    "bad_video = examples_dir + \"bad.wmv\"\n",
    "good_video = examples_dir + \"good.wmv\"\n",
    "\n",
    "# settings\n",
    "turn_on_delay = 5\n",
    "x,y = 200,190\n",
    "w,h = 1070,150\n",
    "frames_limit = 10\n",
    "detection_zones = 6\n",
    "# bound_velocity = 0.006\n",
    "bound_velocity = 0.006\n",
    "\n",
    "# Average for lamps detector\n",
    "average_frame_limit = 8\n",
    "average_images_limit = 40\n",
    "average_images = []\n",
    "index_for_averaging = 0   \n",
    "\n",
    "\n",
    "# Common memory\n",
    "measures = [ [ 0 for i in range(detection_zones) ] for j in range(frames_limit) ]\n",
    "errorDelayCounters = [0]*detection_zones\n",
    "    \n",
    "    \n",
    "class ImageFeature:\n",
    "    def __init__(self, area_ratio):\n",
    "        self.area_ratio=area_ratio\n",
    "        \n",
    "class SegmentAnswer:\n",
    "    def __init__(self, feature, was_detected):\n",
    "        self.feature=feature\n",
    "        self.was_detected=was_detected\n",
    "\n",
    "class FrameBuffer:\n",
    "    def __init__(self):\n",
    "        self.features_array = [ [ ImageFeature(0.0) for i in range(detection_zones) ] for j in range(frames_limit) ]\n",
    "\n",
    "frames_buffer = FrameBuffer()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_contours(img,thresh, label):\n",
    "    # Find contours\n",
    "    contours, hierarchy = cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = sorted(contours, key=cv2.contourArea,reverse=True) \n",
    "    # Select long perimeters only\n",
    "    perimeters = [cv2.arcLength(contours[i],True) for i in range(len(contours))]\n",
    "    listindex=[i for i in range(len(contours)) if perimeters[i]>perimeters[0]/2]\n",
    "    numcards=len(listindex)\n",
    "    # Show image\n",
    "    imgcont = img.copy()\n",
    "    [cv2.drawContours(imgcont, [contours[i]], 0,\n",
    "                      (0,0,255), 1) for i in range(len(contours))]\n",
    "    cv2.imshow(label,imgcont)\n",
    "\n",
    "def printLabel( image, label, upper ):\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX \n",
    "    # org \n",
    "    org = ((50, 50),(50,100))[upper]\n",
    "    # fontScale \n",
    "    fontScale = 1\n",
    "    # Blue color in BGR \n",
    "    color = (255, 0, 0) \n",
    "  \n",
    "    # Line thickness of 2 px \n",
    "    thickness = 2\n",
    "    return cv2.putText(image, label, org, font,  \n",
    "                   fontScale, color, thickness, cv2.LINE_AA)\n",
    "\n",
    "def extract_features(image):\n",
    "    fullArea = image.shape[0]*image.shape[1]\n",
    "    area = cv2.countNonZero(image)\n",
    "    area_ratio = area/fullArea\n",
    "    return ImageFeature(area_ratio)\n",
    "        \n",
    "def process_zone( zone_index, image):\n",
    "    array=frames_buffer.features_array[zone_index]\n",
    "    image_feature = extract_features(image)\n",
    "    \n",
    "    feature = ImageFeature(0.0)\n",
    "    fullArea = image.shape[0]*image.shape[1]\n",
    "    area = cv2.countNonZero(image)\n",
    "    ratio = area/fullArea\n",
    "    if( len(array) > frames_limit):\n",
    "        frames_buffer.features_array[zone_index].pop(0)\n",
    "        return  SegmentAnswer(0.0,False)\n",
    "    frames_buffer.features_array[zone_index].append(ImageFeature(ratio))\n",
    "    # Check the matrix to fill last element with spread\n",
    "    array=frames_buffer.features_array[zone_index]\n",
    "    ratio_array = []\n",
    "    for items in array:\n",
    "        ratio_array.append(items.area_ratio)\n",
    "    f_min = min(ratio_array)\n",
    "    f_max = max(ratio_array)\n",
    "    diffs = []\n",
    "    for index in range(0,len(ratio_array)-1):\n",
    "        diffs.append(math.fabs(ratio_array[index]-ratio_array[index+1]))\n",
    "    if( max(diffs) > bound_velocity ):\n",
    "        return SegmentAnswer(max(diffs),True)\n",
    "    return SegmentAnswer(max(diffs),False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# возвращает [(порог превышен, максимальная производная метрики)]\n",
    "def detect_artifacts(binarized_image,zones_count,x,y,w,h):\n",
    "    answer = []\n",
    "    for zone_index in range(0,zones_count):\n",
    "        zone_width = int(w/zones_count)\n",
    "        rect_x = x + zone_index*zone_width\n",
    "        cropped_zone = binarized_image[y+1:y+h-2,rect_x:rect_x+zone_width-2]\n",
    "        feature = process_zone(zone_index, cropped_zone)\n",
    "        answer.append(feature)\n",
    "    return answer\n",
    "\n",
    "def addZoneRect(color_image, zone_index, zones_count, green_or_red, x,y,w,h ):\n",
    "    zone_width = int(w/zones_count)\n",
    "    rect_x = x + zone_index*zone_width\n",
    "    color = ((1,255,1),(1,1,255))[green_or_red]\n",
    "    dept=(4,1)[green_or_red]\n",
    "    return cv2.rectangle(color_image,(rect_x,y),(rect_x+zone_width,y+h),color,dept)\n",
    "    \n",
    "activation_answers = [0 for i in range(detection_zones)]    \n",
    "counter = 0\n",
    "\n",
    "def get_diff_image(images):\n",
    "    # im_t is the frame of interest; im_tp1 and im_tm1 are, respectively\n",
    "    # the successive and previous frames.\n",
    "    dbp = cv2.absdiff(images[1], images[0])\n",
    "    db0 = cv2.absdiff(images[2], images[0])\n",
    "    dbm = cv2.absdiff(images[1],images[2])\n",
    "    return cv2.bitwise_not( cv2.bitwise_and(cv2.bitwise_and(dbp, dbm),cv2.bitwise_not(db0)))\n",
    "    \n",
    "def set_long_error( zones_count, answer_metrics_pairs, errorDelayCounters):\n",
    "     for zone_index in range(detection_zones):\n",
    "            (answer,metrics)=(answer_metrics_pairs[zone_index].was_detected, answer_metrics_pairs[zone_index].feature)\n",
    "            longError =  errorDelayCounters[zone_index] > 0\n",
    "            if longError:\n",
    "                answer = True\n",
    "                errorDelayCounters[zone_index] =  errorDelayCounters[zone_index] - 1\n",
    "            elif answer:\n",
    "                errorDelayCounters[zone_index] = 4\n",
    "\n",
    "def set_activation_answers(zones_count, answer_metrics_pairs, errorDelayCounters):\n",
    "     for zone_index in range(zones_count):\n",
    "            (answer,metrics)=(answer_metrics_pairs[zone_index].was_detected, answer_metrics_pairs[zone_index].feature)\n",
    "            longError =  errorDelayCounters[zone_index] > 0\n",
    "            if not longError and answer:\n",
    "                activation_answers[zone_index]= metrics                \n",
    "                \n",
    "def calculate_label( is_ready, zones_count, answer_metrics_pairs):\n",
    "    if not is_ready:\n",
    "        return  \"focusing delay\"\n",
    "    label = \"\"\n",
    "    for zone_index in range(detection_zones):\n",
    "        (answer,metrics)=(answer_metrics_pairs[zone_index].was_detected, answer_metrics_pairs[zone_index].feature)\n",
    "        label = label +(\"Y\",\"N\")[answer]+\" \"+\"{:.5f}\".format(metrics)+\" \"\n",
    "    return label\n",
    "        \n",
    "def draw_zone_rectangles( zones_count, answer_metrics_pairs, color_img, errorDelayCounters ):\n",
    "    for zone_index in range(detection_zones):\n",
    "        (answer,metrics)=(answer_metrics_pairs[zone_index].was_detected, answer_metrics_pairs[zone_index].feature)\n",
    "        longError =  errorDelayCounters[zone_index] > 0\n",
    "        if longError:\n",
    "            answer = True\n",
    "        color_img = addZoneRect( color_img, zone_index, detection_zones, answer, x,y,w,h)\n",
    "    return color_img\n",
    "    \n",
    "def plot_average_contours(image,contour_source):\n",
    "    show_contours(image, contour_source, \"Contour\")\n",
    "    \n",
    "def process_average(frame, draw_image):\n",
    "    global average_frame_limit\n",
    "    global average_images_limit\n",
    "    global average_images\n",
    "    global index_for_averaging\n",
    "    \n",
    "    if len(average_images) == average_images_limit:\n",
    "        average_images.append(frame)\n",
    "        dst = average_images[0]\n",
    "        for i in range(len(average_images)):\n",
    "            if i == 0:\n",
    "                pass\n",
    "            else:\n",
    "                alpha = 1.0/(i + 1)\n",
    "                beta = 1.0 - alpha\n",
    "                dst = cv2.addWeighted(average_images[i], alpha, dst, beta, 0.0)\n",
    "        ret,binarizedImage = cv2.threshold(dst,160,255,cv2.THRESH_TOZERO)\n",
    "        kernel = np.ones((8,8),np.uint8)\n",
    "        erosion = cv2.dilate(binarizedImage,kernel,iterations = 15)   \n",
    "        plot_average_contours( draw_image, erosion)\n",
    "    if len(average_images) > average_images_limit:\n",
    "        average_images.pop(0)\n",
    "    index_for_averaging = index_for_averaging + 1\n",
    "    if index_for_averaging > average_frame_limit:\n",
    "        index_for_averaging = 0\n",
    "        \n",
    "        \n",
    "    \n",
    "def process_frame(frame, images, is_ready):\n",
    "    # Frames #\n",
    "    gr_img = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    ret,binarizedImage = cv2.threshold(gr_img,215,255,cv2.THRESH_TOZERO)\n",
    "    color_img = cv2.cvtColor(binarizedImage, cv2.COLOR_GRAY2RGB)\n",
    "    \n",
    "    process_average(binarizedImage, color_img )\n",
    "        \n",
    "    images.append(gr_img)\n",
    "    if len(images) > 3 :\n",
    "        images.pop(0)\n",
    "\n",
    "    if len(images)==3:      \n",
    "        # Frames  \n",
    "        diff_image = get_diff_image(images)\n",
    "        r,binarized_diff = cv2.threshold(diff_image,215,255,cv2.THRESH_TOZERO_INV)\n",
    "        cv2.imshow('Binarized Diff',binarized_diff)\n",
    "        show_contours(frame,binarized_diff,'show_contours')\n",
    "        binarizedImage = binarized_diff\n",
    "    \n",
    "    label = \"\"\n",
    "    label_activation = \"\"\n",
    "    if is_ready:\n",
    "        zones_count =  range(detection_zones)\n",
    "        answer_metrics_pairs = detect_artifacts( binarizedImage, detection_zones,x,y,w,h)\n",
    "        set_long_error( zones_count, answer_metrics_pairs, errorDelayCounters )\n",
    "        label = calculate_label(is_ready,zones_count,answer_metrics_pairs)\n",
    "        color_img = draw_zone_rectangles( zones_count, answer_metrics_pairs, color_img, errorDelayCounters )\n",
    "\n",
    "    for activation in activation_answers:\n",
    "        label_activation = label_activation + \"{:.5f}\".format(activation) + \" \"\n",
    "    finalImage = printLabel(color_img, label,True)\n",
    "    finalImage = printLabel(finalImage, label_activation,False)\n",
    "   # cv2.imshow('Original',frame)\n",
    "    cv2.imshow('Frame',finalImage)\n",
    "\n",
    "def displayProgressBar(capture, currentframe):\n",
    "    nextFrameNo = capture.get(cv2.CAP_PROP_POS_FRAMES)\n",
    "    totalFrames =capture.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    complete = nextFrameNo/totalFrames\n",
    "    return complete\n",
    "\n",
    "def update_print_progress(last_progress, frame, capture):\n",
    "    multiplier = 10000\n",
    "    progress = multiplier*displayProgressBar(capture,frame)\n",
    "    if int(progress)-int(last_progress) >= 1:\n",
    "        print(\"{:.5f}\".format(progress/multiplier))\n",
    "        return progress\n",
    "    return last_progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final\n",
      "[0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "def process_video_file(video_path):\n",
    "    # Focusing delay\n",
    "    start = timer()\n",
    "        \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        return True, \"Error opening video stream or file\"\n",
    "    \n",
    "    images = []\n",
    "    progress = -1\n",
    "    while(cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        if ret == False:\n",
    "            break\n",
    "        # progress = update_print_progress(progress, frame, cap)   \n",
    "        is_ready =  timer() - start > turn_on_delay    \n",
    "        process_frame(frame, images, is_ready)\n",
    "        # Press Q on keyboard to  exit\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "       \n",
    "\n",
    "    # When everything done, release the video capture object\n",
    "    cap.release()\n",
    "\n",
    "    # Closes all the frames\n",
    "    cv2.destroyAllWindows()\n",
    "    return False,\"\"\n",
    "\n",
    "process_video_file(bad_video)\n",
    "print('final')\n",
    "print(activation_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "import random\n",
    "import socket\n",
    "import time\n",
    "\n",
    "ip_addr = ''\n",
    "port = 2002\n",
    "message_max_length = 1024\n",
    "connectionsCount = 0\n",
    "screenFlipper = False\n",
    "msg = '!{0}\"{1}\"{2}\"{3}\"{4}\"{5}'\n",
    "\n",
    "def CreateRandomMessage():\n",
    "    global screenFlipper\n",
    "    global msg\n",
    "    msg_copy = msg\n",
    "    errorFound = random.randint(0,1)\n",
    "    isWorking = random.randint(0,1)\n",
    "    flipping = (0,1)[screenFlipper]\n",
    "    screenFlipper = not screenFlipper\n",
    "    possibility=str(random.randint(0,100)).zfill(3)\n",
    "    size = str(random.randint(0,999)).zfill(3)\n",
    "    msg_copy = msg_copy.format(errorFound,isWorking,flipping,errorFound,possibility,size)\n",
    "    return msg_copy.encode()\n",
    "\n",
    "def SocketCycle(conn):\n",
    "    global message_max_length\n",
    "    while True:\n",
    "        data = conn.recv(message_max_length)\n",
    "        if not data:\n",
    "            break\n",
    "        conn.send(CreateRandomMessage())\n",
    "\n",
    "def SocketHandle(sock):\n",
    "    print(\"Server started\")\n",
    "    global port\n",
    "    sock.bind(('', port))\n",
    "    sock.listen(1)\n",
    "    conn, addr = sock.accept()\n",
    "    print('connected:', addr)\n",
    "    SocketCycle(conn)\n",
    "\n",
    "    \n",
    "def Main():\n",
    "    global connectionsCount\n",
    "    while True:\n",
    "        try:\n",
    "            sock = socket.socket()\n",
    "            SocketHandle(sock)\n",
    "            sock.close()\n",
    "            clear_output(wait=True)\n",
    "            print(\"Server stopped due to disconnect, restarting\")\n",
    "            print(\"Restart count = {0}\".format(connectionsCount))\n",
    "            connectionsCount = connectionsCount + 1\n",
    "        except Exception:\n",
    "            pass\n",
    "    \n",
    "    \n",
    "Main()\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def show_contours(img,thresh):\n",
    "    # Find contours\n",
    "    contours, hierarchy = cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = sorted(contours, key=cv2.contourArea,reverse=True) \n",
    "    # Select long perimeters only\n",
    "    perimeters = [cv2.arcLength(contours[i],True) for i in range(len(contours))]\n",
    "    listindex=[i for i in range(15) if perimeters[i]>perimeters[0]/2]\n",
    "    numcards=len(listindex)\n",
    "    # Show image\n",
    "    imgcont = img.copy()\n",
    "    [cv2.drawContours(imgcont, [contours[i]], 0, (0,255,0), 5) for i in range(len(contours))]\n",
    "    cv2.imshow('f',imgcont)\n",
    "\n",
    "img = cv2.imread('image.png')\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "blur = cv2.GaussianBlur(gray,(1,1),1000)\n",
    "# Prepocess\n",
    "flag, thresh = cv2.threshold(blur, 120, 255, cv2.THRESH_BINARY)\n",
    "show_contours(img,thresh)\n",
    "cv2.waitKey(10000)\n",
    "cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
